python -m src.evaluation.runner --workers 57 --api-provider openai
Scoring id=0 (word_count=296)...
Scoring id=1 (word_count=260)...
Scoring id=2 (word_count=27)...
Scoring id=3 (word_count=262)...
Scoring id=4 (word_count=281)...
Scoring id=5 (word_count=276)...
Scoring id=6 (word_count=296)...
Scoring id=7 (word_count=359)...
Scoring id=8 (word_count=345)...
Scoring id=9 (word_count=258)...
Scoring id=10 (word_count=265)...
Scoring id=11 (word_count=259)...
Scoring id=12 (word_count=309)...
Scoring id=13 (word_count=281)...
Scoring id=14 (word_count=273)...
Scoring id=15 (word_count=293)...
Scoring id=16 (word_count=282)...
Scoring id=17 (word_count=305)...
Scoring id=18 (word_count=285)...
Scoring id=19 (word_count=258)...
Scoring id=20 (word_count=269)...
Scoring id=21 (word_count=258)...
Scoring id=22 (word_count=250)...
Scoring id=23 (word_count=294)...
Scoring id=24 (word_count=318)...
Scoring id=25 (word_count=307)...
Scoring id=26 (word_count=279)...
Scoring id=27 (word_count=288)...
Scoring id=28 (word_count=286)...
Scoring id=29 (word_count=302)...
Scoring id=30 (word_count=323)...
Scoring id=31 (word_count=262)...
Scoring id=32 (word_count=289)...
Scoring id=33 (word_count=299)...
Scoring id=34 (word_count=258)...
Scoring id=35 (word_count=265)...
Scoring id=36 (word_count=285)...
Scoring id=37 (word_count=275)...
Scoring id=38 (word_count=477)...
Scoring id=39 (word_count=310)...
Scoring id=40 (word_count=296)...
Scoring id=41 (word_count=260)...
Scoring id=42 (word_count=269)...
Scoring id=43 (word_count=263)...
Scoring id=44 (word_count=267)...
Scoring id=45 (word_count=308)...
Scoring id=46 (word_count=253)...
Scoring id=47 (word_count=370)...
Scoring id=48 (word_count=493)...
Scoring id=49 (word_count=321)...
Scoring id=50 (word_count=253)...
Scoring id=51 (word_count=252)...
Scoring id=52 (word_count=279)...
Scoring id=53 (word_count=280)...
Scoring id=54 (word_count=256)...
Scoring id=55 (word_count=289)...
Scoring id=56 (word_count=259)...
Task 2 scoring failed: Expecting ',' delimiter: line 89 column 2657 (char 5914)
Task 2 scoring failed: Unterminated string starting at: line 92 column 5555 (char 9816)
Task 2 scoring failed: Expecting ':' delimiter: line 252 column 1230 (char 8409)
Task 2 scoring failed: Unterminated string starting at: line 82 column 5244 (char 8651)
Task 2 scoring failed: Unterminated string starting at: line 48 column 3 (char 2039)
Task 2 scoring failed: Unterminated string starting at: line 292 column 5 (char 11442)
Task 2 scoring failed: Unterminated string starting at: line 12 column 5 (char 223)
Task 2 scoring failed: Unterminated string starting at: line 407 column 12 (char 13112)
Task 2 scoring failed: Expecting property name enclosed in double quotes: line 112 column 3386 (char 8010)
Task 2 scoring failed: Expecting value: line 405 column 1 (char 2222)
Task 2 scoring failed: Expecting ',' delimiter: line 552 column 13 (char 9241)
Task 2 scoring failed: Unterminated string starting at: line 72 column 11 (char 2712)
Task 2 scoring failed: Expecting ',' delimiter: line 82 column 2371 (char 4945)
Task 2 scoring failed: Unterminated string starting at: line 41 column 1553 (char 3138)
Task 2 scoring failed: Unterminated string starting at: line 39 column 4281 (char 5845)
Task 2 scoring failed: Unterminated string starting at: line 335 column 3 (char 13905)
Task 2 scoring failed: Expecting property name enclosed in double quotes: line 379 column 1 (char 13848)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/runner.py", line 64, in <module>
    main()
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/runner.py", line 44, in main
    preds = run_predictions(df, PredictConfig(workers=args.workers, api_provider=args.api_provider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/predictor.py", line 143, in run_predictions
    rows.append(fut.result())
                ^^^^^^^^^^^^
  File "/home/thu/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thu/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/thu/anaconda3/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/predictor.py", line 66, in _predict_one
    result = score_task2_3pass(essay, question=question, llm_client=llm_client)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/app/scoring/pipeline.py", line 69, in score_task2_3pass
    votes = [float(p["overall"]) for p in passes]
                   ~^^^^^^^^^^^
KeyError: 'overall'
thu@Thu-Lenovo:~/master/semester3/IELTS-Writing-Evaluator$ python -m src.evaluation.runner --workers 57 --api-provider openai
Scoring id=0 (word_count=296)...
Scoring id=1 (word_count=260)...
Scoring id=2 (word_count=27)...
Scoring id=3 (word_count=262)...
Scoring id=5 (word_count=276)...
Scoring id=6 (word_count=296)...
Scoring id=7 (word_count=359)...
Scoring id=8 (word_count=345)...
Scoring id=9 (word_count=258)...
Scoring id=4 (word_count=281)...
Scoring id=10 (word_count=265)...
Scoring id=11 (word_count=259)...
Scoring id=12 (word_count=309)...
Scoring id=13 (word_count=281)...
Scoring id=14 (word_count=273)...
Scoring id=15 (word_count=293)...
Scoring id=16 (word_count=282)...
Scoring id=17 (word_count=305)...
Scoring id=19 (word_count=258)...
Scoring id=18 (word_count=285)...
Scoring id=20 (word_count=269)...
Scoring id=21 (word_count=258)...
Scoring id=22 (word_count=250)...
Scoring id=23 (word_count=294)...
Scoring id=24 (word_count=318)...
Scoring id=25 (word_count=307)...
Scoring id=26 (word_count=279)...
Scoring id=27 (word_count=288)...
Scoring id=28 (word_count=286)...
Scoring id=29 (word_count=302)...
Scoring id=30 (word_count=323)...
Scoring id=31 (word_count=262)...
Scoring id=32 (word_count=289)...
Scoring id=33 (word_count=299)...
Scoring id=34 (word_count=258)...
Scoring id=35 (word_count=265)...
Scoring id=36 (word_count=285)...
Scoring id=37 (word_count=275)...
Scoring id=38 (word_count=477)...
Scoring id=39 (word_count=310)...
Scoring id=40 (word_count=296)...
Scoring id=41 (word_count=260)...
Scoring id=42 (word_count=269)...
Scoring id=43 (word_count=263)...
Scoring id=44 (word_count=267)...
Scoring id=45 (word_count=308)...
Scoring id=46 (word_count=253)...
Scoring id=47 (word_count=370)...
Scoring id=48 (word_count=493)...
Scoring id=49 (word_count=321)...
Scoring id=50 (word_count=253)...
Scoring id=51 (word_count=252)...
Scoring id=52 (word_count=279)...
Scoring id=53 (word_count=280)...
Scoring id=54 (word_count=256)...
Scoring id=55 (word_count=289)...
Scoring id=56 (word_count=259)...
Task 2 scoring failed: Expecting property name enclosed in double quotes: line 83 column 11 (char 5294)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/runner.py", line 64, in <module>
    main()
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/runner.py", line 44, in main
    preds = run_predictions(df, PredictConfig(workers=args.workers, api_provider=args.api_provider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/predictor.py", line 143, in run_predictions
    rows.append(fut.result())
                ^^^^^^^^^^^^
  File "/home/thu/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/thu/anaconda3/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/thu/anaconda3/lib/python3.12/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/evaluation/predictor.py", line 66, in _predict_one
    result = score_task2_3pass(essay, question=question, llm_client=llm_client)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/app/scoring/pipeline.py", line 115, in score_task2_3pass
    validate_score_response(result)
  File "/home/thu/master/semester3/IELTS-Writing-Evaluator/src/app/validation/schemas.py", line 44, in validate_score_response
    _get_validator("score_response.v1.json").validate(payload)
  File "/home/thu/anaconda3/lib/python3.12/site-packages/jsonschema/validators.py", line 451, in validate
    raise error
jsonschema.exceptions.ValidationError: 7.2 is not a multiple of 0.5

Failed validating 'multipleOf' in schema['properties']['votes']['items']:
    {'type': 'number', 'minimum': 0, 'maximum': 9, 'multipleOf': 0.5}

On instance['votes'][0]:
    7.2