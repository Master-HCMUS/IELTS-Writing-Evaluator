{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2cdec8",
   "metadata": {},
   "source": [
    "# Notebook: Chấm điểm IELTS Writing Task 2 bằng Qwen2-7B (Kaggle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94333b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Cài đặt và nhập các thư viện cần thiết\n",
    "!pip install --upgrade pip\n",
    "!pip install -q transformers accelerate torch jsonschema\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import base64\n",
    "from jsonschema import validate, ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Tải và nạp mô hình Qwen2-7B\n",
    "MODEL_NAME = \"Qwen/Qwen2-7B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab923f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Định nghĩa schema đầu vào theo score_request.v1.json\n",
    "score_request_schema = {\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"$id\": \"score_request.v1.json\",\n",
    "    \"title\": \"ScoreRequestV1\",\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"task_type\": {\"type\": \"string\", \"enum\": [\"task1\", \"task2\"]},\n",
    "        \"essay\": {\"type\": \"string\", \"minLength\": 1, \"maxLength\": 20000},\n",
    "        \"question\": {\"type\": \"string\", \"minLength\": 5, \"maxLength\": 1000},\n",
    "        \"image_base64\": {\"type\": \"string\"},\n",
    "        \"options\": {\n",
    "            \"type\": \"object\",\n",
    "            \"additionalProperties\": False,\n",
    "            \"properties\": {\n",
    "                \"max_evidence\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 3}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"task_type\", \"essay\"],\n",
    "    \"allOf\": [\n",
    "        {\n",
    "            \"if\": {\"properties\": {\"task_type\": {\"const\": \"task1\"}}},\n",
    "            \"then\": {\"required\": [\"essay\"]}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def validate_score_request(data):\n",
    "    try:\n",
    "        validate(instance=data, schema=score_request_schema)\n",
    "        print(\"Input hợp lệ theo schema.\")\n",
    "        return True\n",
    "    except ValidationError as e:\n",
    "        print(f\"Lỗi schema: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eac474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Tiền xử lý dữ liệu đầu vào (essay, question, image_base64)\n",
    "def preprocess_input(data):\n",
    "    essay = data.get(\"essay\", \"\")\n",
    "    question = data.get(\"question\", \"\")\n",
    "    image = None\n",
    "    if data.get(\"image_base64\"):\n",
    "        try:\n",
    "            image = base64.b64decode(data[\"image_base64\"])\n",
    "        except Exception:\n",
    "            image = None\n",
    "    return essay, question, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Tạo hàm chấm điểm sử dụng Qwen2-7B\n",
    "\n",
    "def get_standard_task2_prompt(essay, question):\n",
    "    # Prompt chuẩn hóa giống src/app/prompts/task2.py\n",
    "    return (\n",
    "        f\"You are an IELTS Writing Task 2 examiner.\\n\"\n",
    "        f\"Score the following essay according to the IELTS rubric (0-9) and provide feedback for each criterion (Task Response, Coherence and Cohesion, Lexical Resource, Grammatical Range and Accuracy).\\n\"\n",
    "        f\"Question: {question}\\nEssay: {essay}\\n\"\n",
    "        f\"Return a JSON object with keys: overall, per_criterion (dict), feedback (dict).\"\n",
    "    )\n",
    "\n",
    "def score_ielts_task2_qwen2(essay, question, model, tokenizer, max_new_tokens=512):\n",
    "    prompt = get_standard_task2_prompt(essay, question)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    import re\n",
    "    match = re.search(r\"\\{.*\\}\", result, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(0))\n",
    "        except Exception:\n",
    "            return {\"error\": \"Không parse được JSON từ kết quả model.\"}\n",
    "    return {\"error\": \"Không tìm thấy JSON trong kết quả model.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62378a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Chạy thử nghiệm chấm điểm với dữ liệu mẫu\n",
    "sample_data = {\n",
    "    \"task_type\": \"task2\",\n",
    "    \"essay\": \"In today’s world, technology has become an integral part of our lives. Some people believe that it has improved our quality of life, while others think it has made life more complicated. Discuss both views and give your own opinion.\",\n",
    "    \"question\": \"Some people believe that technology has improved our quality of life, while others think it has made life more complicated. Discuss both views and give your own opinion.\",\n",
    "    \"options\": {\"max_evidence\": 2}\n",
    "}\n",
    "\n",
    "if validate_score_request(sample_data):\n",
    "    essay, question, _ = preprocess_input(sample_data)\n",
    "    result = score_ielts_task2_qwen2(essay, question, model, tokenizer)\n",
    "else:\n",
    "    result = {\"error\": \"Input không hợp lệ.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdd488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Hiển thị kết quả chấm điểm\n",
    "import pprint\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2e45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5.1: Nạp prompt chuẩn từ mã nguồn (theo src/app/prompts/task2.py)\n",
    "def get_standard_task2_prompt(essay, question):\n",
    "    # Prompt chuẩn hóa giống src/app/prompts/task2.py\n",
    "    return (\n",
    "        f\"You are an IELTS Writing Task 2 examiner.\\n\"\n",
    "        f\"Score the following essay according to the IELTS rubric (0-9) and provide feedback for each criterion (Task Response, Coherence and Cohesion, Lexical Resource, Grammatical Range and Accuracy).\\n\"\n",
    "        f\"Question: {question}\\nEssay: {essay}\\n\"\n",
    "        f\"Return a JSON object with keys: overall, per_criterion (dict), feedback (dict).\"\n",
    "    )\n",
    "\n",
    "# Sửa lại hàm chấm điểm để dùng prompt chuẩn\n",
    "\n",
    "def score_ielts_task2_oss20b(essay, question, model, tokenizer, max_new_tokens=512):\n",
    "    prompt = get_standard_task2_prompt(essay, question)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    import re\n",
    "    match = re.search(r\"\\{.*\\}\", result, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(0))\n",
    "        except Exception:\n",
    "            return {\"error\": \"Không parse được JSON từ kết quả model.\"}\n",
    "    return {\"error\": \"Không tìm thấy JSON trong kết quả model.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 8: Nạp và test batch với dataset mẫu (giả lập giống src/evaluation/datasets/hf_task2.py)\n",
    "import pandas as pd\n",
    "\n",
    "# Giả lập dataset mẫu (có thể thay bằng file thật nếu có)\n",
    "dataset = [\n",
    "    {\n",
    "        \"task_type\": \"task2\",\n",
    "        \"essay\": \"Some people think that the best way to increase road safety is to increase the minimum legal age for driving cars or riding motorbikes. To what extent do you agree or disagree?\",\n",
    "        \"question\": \"Some people think that the best way to increase road safety is to increase the minimum legal age for driving cars or riding motorbikes. To what extent do you agree or disagree?\",\n",
    "        \"options\": {\"max_evidence\": 2}\n",
    "    },\n",
    "    {\n",
    "        \"task_type\": \"task2\",\n",
    "        \"essay\": \"Many people believe that social networking sites have a huge negative impact on both individuals and society. To what extent do you agree or disagree?\",\n",
    "        \"question\": \"Many people believe that social networking sites have a huge negative impact on both individuals and society. To what extent do you agree or disagree?\",\n",
    "        \"options\": {\"max_evidence\": 2}\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "for i, row in enumerate(dataset):\n",
    "    if validate_score_request(row):\n",
    "        essay, question, _ = preprocess_input(row)\n",
    "        result = score_ielts_task2_qwen2(essay, question, model, tokenizer)\n",
    "        results.append({\"index\": i, \"result\": result})\n",
    "    else:\n",
    "        results.append({\"index\": i, \"result\": {\"error\": \"Input không hợp lệ.\"}})\n",
    "\n",
    "# Hiển thị kết quả batch\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21026aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 9: Đảm bảo output đúng format chuẩn score_response.v1.json\n",
    "def validate_score_response_format(response):\n",
    "    # Định nghĩa schema đơn giản hóa cho score_response.v1.json\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"overall\": {\"type\": \"number\"},\n",
    "            \"per_criterion\": {\"type\": \"object\"},\n",
    "            \"feedback\": {\"type\": \"object\"}\n",
    "        },\n",
    "        \"required\": [\"overall\", \"per_criterion\", \"feedback\"]\n",
    "    }\n",
    "    try:\n",
    "        validate(instance=response, schema=schema)\n",
    "        return True\n",
    "    except ValidationError as e:\n",
    "        print(f\"Output không đúng format chuẩn: {e}\")\n",
    "        return False\n",
    "\n",
    "# Kiểm tra kết quả batch\n",
    "for r in results:\n",
    "    print(f\"Index {r['index']}:\", validate_score_response_format(r['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3dfe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 10: Tải và chuẩn hóa dataset chillies/IELTS-writing-task-2-evaluation\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset_name = \"chillies/IELTS-writing-task-2-evaluation\"\n",
    "df = load_dataset(dataset_name, split=\"test\").to_pandas()\n",
    "# Chuẩn hóa cột\n",
    "if \"band\" in df.columns:\n",
    "    df = df.rename(columns={\"band\": \"band_true\"})\n",
    "if \"id\" not in df.columns:\n",
    "    df[\"id\"] = range(len(df))\n",
    "df[\"word_count\"] = df[\"essay\"].astype(str).str.split().map(len)\n",
    "df = df[[\"id\", \"prompt\", \"essay\", \"band_true\", \"word_count\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64742cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 11: Batch scoring toàn bộ tập test bằng Qwen2-7B\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    data = {\n",
    "        \"task_type\": \"task2\",\n",
    "        \"essay\": row[\"essay\"],\n",
    "        \"question\": row[\"prompt\"],\n",
    "        \"options\": {\"max_evidence\": 2}\n",
    "    }\n",
    "    if validate_score_request(data):\n",
    "        essay, question, _ = preprocess_input(data)\n",
    "        result = score_ielts_task2_qwen2(essay, question, model, tokenizer)\n",
    "        band_pred = result.get(\"overall\", None)\n",
    "    else:\n",
    "        band_pred = None\n",
    "    results.append({\"id\": row[\"id\"], \"band_true\": row[\"band_true\"], \"band_pred\": band_pred})\n",
    "\n",
    "df_pred = pd.DataFrame(results)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 12: Tính toán các chỉ số đánh giá MAE, RMSE, QWK, Pearson, Spearman\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "def safe_round(x):\n",
    "    try:\n",
    "        return round(float(x))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df_pred = df_pred.dropna(subset=[\"band_pred\"]).copy()\n",
    "df_pred[\"band_pred_round\"] = df_pred[\"band_pred\"].map(safe_round)\n",
    "\n",
    "mae = mean_absolute_error(df_pred[\"band_true\"], df_pred[\"band_pred\"])\n",
    "rmse = mean_squared_error(df_pred[\"band_true\"], df_pred[\"band_pred\"] , squared=False)\n",
    "qwk = cohen_kappa_score(df_pred[\"band_true\"], df_pred[\"band_pred_round\"], weights=\"quadratic\")\n",
    "pearson = pearsonr(df_pred[\"band_true\"], df_pred[\"band_pred\"])[0]\n",
    "spearman = spearmanr(df_pred[\"band_true\"], df_pred[\"band_pred\"])[0]\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"QWK: {qwk:.4f}\")\n",
    "print(f\"Pearson: {pearson:.4f}\")\n",
    "print(f\"Spearman: {spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec685910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 13: Hiển thị bảng so sánh kết quả dự đoán và thực tế\n",
    "df_pred[[\"id\", \"band_true\", \"band_pred\", \"band_pred_round\"]].head(20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
